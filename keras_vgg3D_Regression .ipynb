{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae33f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import MaxPool2D, MaxPool3D, Flatten, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查GPU\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17d5c0",
   "metadata": {},
   "source": [
    "# 高光譜轉換模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d55243ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrumTransfer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.extend_mode = 0\n",
    "        self.B = None\n",
    "        self.C = None\n",
    "        self.M = None\n",
    "        self.TransM = None\n",
    "        self.TransMin = 0.0\n",
    "        self.TransMax = 1.0\n",
    "        \n",
    "    def get_extend(self, src_rgb):\n",
    "        \n",
    "        extend = None\n",
    "\n",
    "        if self.extend_mode == 0:\n",
    "            extend = np.array([src_rgb[:,0], src_rgb[:,1], src_rgb[:,2], np.power(src_rgb[:,0],2), np.power(src_rgb[:,1],2), np.power(src_rgb[:,2],2)])\n",
    "        elif self.extend_mode == 1:\n",
    "            extend = np.array([src_rgb[:,0], src_rgb[:,1], src_rgb[:,2], np.power(src_rgb[:,0],2), np.power(src_rgb[:,1],2), np.power(src_rgb[:,2],2),src_rgb[:,0]* src_rgb[:,1],src_rgb[:,0]* src_rgb[:,2],src_rgb[:,1]* src_rgb[:,2]])\n",
    "        elif self.extend_mode == 2:\n",
    "            extend = np.array([src_rgb[:,0], src_rgb[:,1], src_rgb[:,2], np.power(src_rgb[:,0],2), np.power(src_rgb[:,1],2), np.power(src_rgb[:,2],2),src_rgb[:,0]* src_rgb[:,1],src_rgb[:,0]* src_rgb[:,2],src_rgb[:,1]* src_rgb[:,2], np.power(src_rgb[:,0],3), np.power(src_rgb[:,1],3), np.power(src_rgb[:,2],3)])\n",
    "\n",
    "        return extend\n",
    "    \n",
    "    def prepare(self):\n",
    "        self.TransM = np.dot(self.M.T, self.B)\n",
    "        return\n",
    "    \n",
    "    def load(self, setup_file):\n",
    "        weight = np.load(setup_file)\n",
    "        \n",
    "        self.M = weight[\"a\"]\n",
    "        self.B = weight[\"b\"]\n",
    "        self.C = weight[\"c\"]\n",
    "        \n",
    "#         self.TransMin = weight['d'][0]\n",
    "#         self.TransMax = weight['d'][1]\n",
    "        \n",
    "        self.extend_mode = weight['e'][0]\n",
    "        \n",
    "        self.prepare()\n",
    "        \n",
    "        return\n",
    " \n",
    "    def transfer1D(self, src_data):\n",
    "        \n",
    "        src_data = src_data.astype(np.float32)\n",
    "\n",
    "        tar_sepc = np.dot(self.get_extend(src_data).T, self.TransM) + self.C\n",
    "        \n",
    "        tar_sepc = (tar_sepc - self.TransMin) / (self.TransMax - self.TransMin)\n",
    "\n",
    "        return tar_sepc\n",
    "    \n",
    "    def transfer(self, src_data):\n",
    "        \n",
    "        src_data = src_data.astype(np.float32)\n",
    "        \n",
    "        src_shape = src_data.shape\n",
    "\n",
    "        if len(src_shape) >= 3:\n",
    "            src_data = src_data.reshape(-1, src_shape[-1])\n",
    "\n",
    "        tar_sepc = np.dot(self.get_extend(src_data).T, self.TransM) + self.C\n",
    "\n",
    "        if len(src_shape) >= 3:\n",
    "            tar_sepc = tar_sepc.持reshape(src_shape[0:-1] + tuple([self.C.shape[0]]))\n",
    "        \n",
    "        tar_sepc = (tar_sepc - self.TransMin) / (self.TransMax - self.TransMin)\n",
    "        \n",
    "        return tar_sepc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e043303",
   "metadata": {},
   "source": [
    "建立LUT\n",
    "\n",
    "COLOR -> SPECTRUM\n",
    "\n",
    "RGB 0-255\n",
    "\n",
    "256*256*256 *401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d66ca2",
   "metadata": {},
   "source": [
    "# 資料產生器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f741fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, data_path:str, shuffle=True, batch_size = 4, image_shape = (64,64,11)):\n",
    "        'Initialization'        \n",
    "        self.transfer = SpectrumTransfer()\n",
    "        self.transfer.load(\"weight.npz\")\n",
    "        \n",
    "        self.data_path = data_path\n",
    "        self.path_list = os.listdir(data_path) # 列出所有圖片檔名  \n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.image_shape = image_shape\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        self.n_classes = 4\n",
    "        \n",
    "        self.label_dict = dict()\n",
    "        self.label_dict['good'] = 1.0/4.0\n",
    "        self.label_dict['normal'] = 2.0/4.0\n",
    "        self.label_dict['unhealthy'] = 3.0/4.0\n",
    "        self.label_dict['very unhealthy'] = 4.0/4.0\n",
    "        \n",
    "        self.data_dict = dict()\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.path_list) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.path_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "             \n",
    "    def __data_generation(self, tar_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        \n",
    "        X = np.empty(([self.batch_size] + list(self.image_shape)))\n",
    "        y = np.empty((self.batch_size), dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(tar_ids):\n",
    "            \n",
    "            trans_spec = None\n",
    "            label = None\n",
    "            \n",
    "            if (ID in self.data_dict):\n",
    "                trans_spec, label = self.data_dict[ID]\n",
    "            else:\n",
    "                \n",
    "                img_path = self.path_list[ID]\n",
    "\n",
    "                img_key = img_path.split('.')[0]\n",
    "\n",
    "                label = self.label_dict.get(img_key, -1)\n",
    "\n",
    "                img_path = os.path.join(self.data_path, img_path)# 取得圖片完整路徑\n",
    "                np_img = cv2.imread(img_path)\n",
    "\n",
    "                trans_spec = self.transfer.transfer(np_img)[:,:,::40].astype('float32')\n",
    "                \n",
    "                self.data_dict[ID] = [trans_spec, label]\n",
    "             \n",
    "            X[i,] = trans_spec\n",
    "            y[i] = label\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615c6163",
   "metadata": {},
   "source": [
    "# 定義模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input  \n",
    "input_data = Input(shape =(64,64,11,1))\n",
    "\n",
    "# 1st Conv Block\n",
    "x = Conv3D (filters =8, kernel_size =3, padding ='same', activation='relu')(input_data)\n",
    "x = MaxPool3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "\n",
    "# 2nd Conv Block\n",
    "x = Conv3D (filters =16, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "x = MaxPool3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "\n",
    "# 3rd Conv block  \n",
    "x = Conv3D (filters =32, kernel_size =3, padding ='same', activation='relu')(x)  \n",
    "x = MaxPool3D(pool_size =2, strides =2, padding ='same')(x)\n",
    "\n",
    "# Fully connected layers  \n",
    "x = Flatten()(x) \n",
    "x = Dense(units = 4096, activation ='relu')(x) \n",
    "x = Dense(units = 256, activation ='relu')(x) \n",
    "output_data = Dense(units = 1)(x)\n",
    "\n",
    "# creating the model\n",
    "model = Model (inputs=input_data, outputs=output_data)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81c94f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics=['accuracy', 'MeanSquaredError'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a96816a",
   "metadata": {},
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "train_data_path = 'D:\\\\AIR POLUTION\\\\TEST\\\\SplitTraining\\\\Train'\n",
    "test_data_path = 'D:\\\\AIR POLUTION\\\\TEST\\\\SplitTraining\\\\Test'\n",
    "\n",
    "shuffle=True\n",
    "batch_size = 4\n",
    "image_shape = (64,64,11)\n",
    "\n",
    "train_generator = DataGenerator(train_data_path, shuffle, batch_size, image_shape)\n",
    "test_generator = DataGenerator(test_data_path, shuffle, batch_size, image_shape)\n",
    "\n",
    "# Train model on dataset\n",
    "history = model.fit(x=train_generator,epochs=epochs, validation_data = test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab284a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "#  Accuracy\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "# mean_squared_error\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.title('model mean_squared_error')\n",
    "plt.ylabel('mean_squared_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4f354",
   "metadata": {},
   "source": [
    "# 儲存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b93732",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg3D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a438a",
   "metadata": {},
   "source": [
    "# 匯出ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "081daa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\envs\\test\\lib\\site-packages\\tf2onnx\\tf_loader.py:715: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\envs\\test\\lib\\site-packages\\tf2onnx\\tf_loader.py:715: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "input_signature = [tf.TensorSpec([None, 64, 64, 11, 1], tf.float32, name='x')]\n",
    "# Use from_function for tf functions\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature, opset=13)\n",
    "onnx.save(onnx_model, \"model_VGG_3D_reg.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1787f",
   "metadata": {},
   "source": [
    "# 更新模型(OPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c3366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "src_file = \"model_VGG_3D_reg.onnx\"\n",
    "tar_file = 'D:\\\\SW_HS\\\\HSEnv\\\\HSEnvPredict\\\\HSEnvPredict\\\\bin\\\\x64\\\\Debug\\\\VGG_3D_model.onnx'\n",
    "\n",
    "shutil.copyfile(src_file, tar_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
